{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Classifier with CNTK (no Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with code provided by the [Transfer Learning example](https://github.com/Microsoft/CNTK/tree/master/Examples/Image/TransferLearning) in the [CNTK repo](https://github.com/Microsoft/CNTK). CNTK binaries are installed on a Data Science Virtual Machine, however not the sample code, which is what we've after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CNTK'...\n",
      "remote: Enumerating objects: 71, done.\u001b[K\n",
      "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
      "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
      "remote: Total 214632 (delta 33), reused 20 (delta 8), pack-reused 214561\u001b[K\n",
      "Receiving objects: 100% (214632/214632), 906.19 MiB | 58.67 MiB/s, done.\n",
      "Resolving deltas: 100% (156018/156018), done.\n",
      "Checking connectivity... done.\n",
      "Checking out files: 100% (3078/3078), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Microsoft/CNTK.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the path to the module that downloads models pretrained using CNTK and the path to the Transfer Learning example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), 'CNTK', 'PretrainedModels'))\n",
    "sys.path.append(os.path.join(os.getcwd(), 'CNTK', 'Examples', 'Image', 'TransferLearning'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "import cntk, requests, shutil, subprocess\n",
    "print (cntk.__version__)\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from __future__ import print_function\n",
    "from download_model import * # From CNTK repo\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from TransferLearning import * # From CNTK repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We follow the example and download ResNet 18 trained with CNTK using ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model from https://www.cntk.ai/Models/CNTK_Pretrained/ResNet18_ImageNet_CNTK.model, may take a while...\n",
      "Saved model as /data/home/graeme/notebooks/openhack/CNTK/PretrainedModels/ResNet18_ImageNet_CNTK.model\n"
     ]
    }
   ],
   "source": [
    "download_model_by_name(\"ResNet18_ImageNet_CNTK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm you can see ResNet18_ImageNet_CNTK.model in ~/CNTK/PretrainedModels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a function to create train and validate folders. The function splits the content of the source folder, preserving the subfolders of the source folder when copying images to the train folder, and copies the remainder directly to the validate folder.\n",
    "\n",
    "Images are also resized to (224, 224) to match the input for the ResNet 18 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_validate_folders(source_folder_path, train_folder_path, validate_folder_path, size, validate_size=0.30):\n",
    "    if (os.path.isdir(train_folder_path)) and (os.path.exists(train_folder_path)):\n",
    "        shutil.rmtree(train_folder_path)\n",
    "        \n",
    "    if (os.path.isdir(validate_folder_path)) and (os.path.exists(validate_folder_path)):\n",
    "        shutil.rmtree(validate_folder_path)\n",
    "    \n",
    "    os.makedirs(validate_folder_path)\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(source_folder_path):\n",
    "        for dirname in dirnames:\n",
    "            files = os.listdir(os.path.join(dirpath, dirname))\n",
    "            train, validate = train_test_split(files, test_size=validate_size)\n",
    "            \n",
    "            train_output_path = os.path.join(train_folder_path, dirname)\n",
    "            \n",
    "            os.makedirs(train_output_path)\n",
    "            \n",
    "            for file_name in train:\n",
    "                src = os.path.join(dirpath, dirname, file_name)\n",
    "                dst = os.path.join(train_output_path, '{0}.jpg'.format(file_name.split('.')[0]))\n",
    "                image = Image.open(src)\n",
    "                new_image = resize_image(image, size)\n",
    "                new_image.save(dst)\n",
    "            \n",
    "            for file_name in validate:\n",
    "                src = os.path.join(dirpath, dirname, file_name)\n",
    "                dst = os.path.join(validate_folder_path, '{0}.jpg'.format(file_name.split('.')[0]))\n",
    "                image = Image.open(src)\n",
    "                new_image = resize_image(image, size)\n",
    "                new_image.save(dst)\n",
    "                \n",
    "def resize_image(image, size):\n",
    "    if np.array(image).shape[2] == 4:\n",
    "        image = image.convert('RGB')\n",
    "        \n",
    "    image.thumbnail(size, Image.ANTIALIAS)\n",
    "    new_image = Image.new(\"RGB\", size, (255, 255, 255))\n",
    "    new_image.paste(image, (int((size[0] - image.size[0]) / 2), int((size[1] - image.size[1]) / 2)))\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three functions are copied from ~/CNTK/Examples/Image/TransferLearning/TransferLearing_Extended.py to create the file that maps each image to its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map_file_from_folder(root_folder, class_mapping, include_unknown=False):\n",
    "    map_file_name = os.path.join(root_folder, \"map.txt\")\n",
    "    lines = []\n",
    "    for class_id in range(0, len(class_mapping)):\n",
    "        folder = os.path.join(root_folder, class_mapping[class_id])\n",
    "        if os.path.exists(folder):\n",
    "            for entry in os.listdir(folder):\n",
    "                filename = os.path.join(folder, entry)\n",
    "                if os.path.isfile(filename) and os.path.splitext(filename)[1] in file_endings:\n",
    "                    lines.append(\"{0}\\t{1}\\n\".format(filename, class_id))\n",
    "\n",
    "    if include_unknown:\n",
    "        for entry in os.listdir(root_folder):\n",
    "            filename = os.path.join(root_folder, entry)\n",
    "            if os.path.isfile(filename) and os.path.splitext(filename)[1] in file_endings:\n",
    "                lines.append(\"{0}\\t-1\\n\".format(filename))\n",
    "\n",
    "    lines.sort()\n",
    "    with open(map_file_name , 'w') as map_file:\n",
    "        for line in lines:\n",
    "            map_file.write(line)\n",
    "\n",
    "    return map_file_name\n",
    "\n",
    "def create_class_mapping_from_folder(root_folder):\n",
    "    classes = []\n",
    "    for _, directories, _ in os.walk(root_folder):\n",
    "        for directory in directories:\n",
    "            classes.append(directory)\n",
    "    classes.sort()\n",
    "    return np.asarray(classes)\n",
    "\n",
    "def format_output_line(img_name, true_class, probs, class_mapping, top_n=3):\n",
    "    class_probs = np.column_stack((probs, class_mapping)).tolist()\n",
    "    class_probs.sort(key=lambda x: float(x[0]), reverse=True)\n",
    "    top_n = min(top_n, len(class_mapping)) if top_n > 0 else len(class_mapping)\n",
    "    true_class_name = class_mapping[true_class] if true_class >= 0 else 'unknown'\n",
    "    line = '[{\"class\": \"%s\", \"predictions\": {' % true_class_name\n",
    "    for i in range(0, top_n):\n",
    "        line = '%s\"%s\":%.3f, ' % (line, class_probs[i][1], float(class_probs[i][0]))\n",
    "    line = '%s}, \"image\": \"%s\"}]\\n' % (line[:-2], img_name.replace('\\\\', '/').rsplit('/', 1)[1])\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also copy the function to train and evaluate our new model, adding a statement to return the new model when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(_base_model_file, _train_image_folder, _test_image_folder, _results_file, _new_model_file, num_epochs, testing = False):\n",
    "    # check for model and data existence\n",
    "    if not (os.path.exists(_base_model_file) and os.path.exists(_train_image_folder) and os.path.exists(_test_image_folder)):\n",
    "        print(\"Please run 'python install_data_and_model.py' first to get the required data and model.\")\n",
    "        exit(0)\n",
    "\n",
    "    # get class mapping and map files from train and test image folder\n",
    "    class_mapping = create_class_mapping_from_folder(_train_image_folder)\n",
    "    train_map_file = create_map_file_from_folder(_train_image_folder, class_mapping)\n",
    "    test_map_file = create_map_file_from_folder(_test_image_folder, class_mapping, include_unknown=True)\n",
    "    \n",
    "    # train\n",
    "    trained_model = train_model(_base_model_file,\n",
    "                                feature_node_name,\n",
    "                                last_hidden_node_name,\n",
    "                                image_width,\n",
    "                                image_height,\n",
    "                                num_channels,\n",
    "                                len(class_mapping),\n",
    "                                train_map_file,\n",
    "                                num_epochs=num_epochs,\n",
    "                                freeze=True)\n",
    "\n",
    "    if not testing:\n",
    "        trained_model.save(_new_model_file)\n",
    "        print(\"Stored trained model at %s\" % _new_model_file)\n",
    "\n",
    "    # evaluate test images\n",
    "    with open(_results_file, 'w') as output_file:\n",
    "        with open(test_map_file, \"r\") as input_file:\n",
    "            for line in input_file:\n",
    "                tokens = line.rstrip().split('\\t')\n",
    "                img_file = tokens[0]\n",
    "                true_label = int(tokens[1])\n",
    "                probs = eval_single_image(trained_model, img_file, image_width, image_height)\n",
    "                formatted_line = format_output_line(img_file, true_label, probs, class_mapping)\n",
    "                output_file.write(formatted_line)\n",
    "\n",
    "    print(\"Done. Wrote output to %s\" % _results_file)\n",
    "    \n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be able to view the progress of training by seeing a plot of the training loss and validation loss and so change ~/CNTK/Examples/Image/TransferLearning/TransferLearning.py to use TensorBoard.\n",
    "\n",
    "Open ~/CNTK/Examples/Image/TransferLearning/TransferLearning.py and make the following changes:\n",
    "\n",
    "- Replace line 24 with `from cntk.logging import log_number_of_parameters, ProgressPrinter, TensorBoardProgressWriter`\n",
    "- Replace line 120 with `    progress_writers = [ProgressPrinter(tag='Training', num_epochs=num_epochs), TensorBoardProgressWriter(freq=10, log_dir=os.path.join(os.getcwd(), 'log'), model=tl_model)]`, and\n",
    "- Replace line 121 with `trainer = Trainer(tl_model, (ce, pe), learner, progress_writers)`\n",
    "\n",
    "File > Save."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, create the folder used by TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(os.getcwd(), 'log')\n",
    "\n",
    "if not os.path.exists(log_path):\n",
    "    os.makedirs(log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, configure the training run and start training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training transfer learning model for 30 epochs (epoch_size = 1480).\n",
      "Training 6156 parameters in 2 parameter tensors.\n",
      "Learning rate per minibatch: 0.2\n",
      "Momentum per minibatch: 0.9\n",
      "Finished Epoch[1 of 30]: [Training] loss = 1.054200 * 1480, metric = 29.39% * 1480 9.010s (164.3 samples/s);\n",
      "Finished Epoch[2 of 30]: [Training] loss = 0.134829 * 1480, metric = 4.66% * 1480 3.406s (434.5 samples/s);\n",
      "Finished Epoch[3 of 30]: [Training] loss = 0.087793 * 1480, metric = 2.77% * 1480 3.413s (433.6 samples/s);\n",
      "Finished Epoch[4 of 30]: [Training] loss = 0.067547 * 1480, metric = 2.43% * 1480 3.417s (433.1 samples/s);\n",
      "Finished Epoch[5 of 30]: [Training] loss = 0.044241 * 1480, metric = 1.22% * 1480 3.418s (433.0 samples/s);\n",
      "Finished Epoch[6 of 30]: [Training] loss = 0.049837 * 1480, metric = 0.95% * 1480 3.430s (431.5 samples/s);\n",
      "Finished Epoch[7 of 30]: [Training] loss = 0.050199 * 1480, metric = 1.69% * 1480 3.430s (431.5 samples/s);\n",
      "Finished Epoch[8 of 30]: [Training] loss = 0.074643 * 1480, metric = 2.30% * 1480 3.420s (432.7 samples/s);\n",
      "Finished Epoch[9 of 30]: [Training] loss = 0.033787 * 1480, metric = 0.81% * 1480 3.420s (432.7 samples/s);\n",
      "Finished Epoch[10 of 30]: [Training] loss = 0.041313 * 1480, metric = 1.22% * 1480 3.429s (431.6 samples/s);\n",
      "Learning rate per minibatch: 0.1\n",
      "Finished Epoch[11 of 30]: [Training] loss = 0.030978 * 1480, metric = 0.61% * 1480 3.413s (433.6 samples/s);\n",
      "Finished Epoch[12 of 30]: [Training] loss = 0.022967 * 1480, metric = 0.54% * 1480 3.450s (429.0 samples/s);\n",
      "Finished Epoch[13 of 30]: [Training] loss = 0.018020 * 1480, metric = 0.27% * 1480 3.462s (427.5 samples/s);\n",
      "Finished Epoch[14 of 30]: [Training] loss = 0.020236 * 1480, metric = 0.34% * 1480 3.430s (431.5 samples/s);\n",
      "Finished Epoch[15 of 30]: [Training] loss = 0.015022 * 1480, metric = 0.20% * 1480 3.401s (435.2 samples/s);\n",
      "Finished Epoch[16 of 30]: [Training] loss = 0.013446 * 1480, metric = 0.07% * 1480 3.429s (431.6 samples/s);\n",
      "Finished Epoch[17 of 30]: [Training] loss = 0.022985 * 1480, metric = 0.34% * 1480 3.449s (429.1 samples/s);\n",
      "Finished Epoch[18 of 30]: [Training] loss = 0.015745 * 1480, metric = 0.14% * 1480 3.419s (432.9 samples/s);\n",
      "Finished Epoch[19 of 30]: [Training] loss = 0.017427 * 1480, metric = 0.27% * 1480 3.462s (427.5 samples/s);\n",
      "Finished Epoch[20 of 30]: [Training] loss = 0.012931 * 1480, metric = 0.14% * 1480 3.438s (430.5 samples/s);\n",
      "Finished Epoch[21 of 30]: [Training] loss = 0.017317 * 1480, metric = 0.47% * 1480 3.480s (425.3 samples/s);\n",
      "Finished Epoch[22 of 30]: [Training] loss = 0.015311 * 1480, metric = 0.20% * 1480 3.436s (430.7 samples/s);\n",
      "Finished Epoch[23 of 30]: [Training] loss = 0.014161 * 1480, metric = 0.20% * 1480 3.470s (426.5 samples/s);\n",
      "Finished Epoch[24 of 30]: [Training] loss = 0.013147 * 1480, metric = 0.20% * 1480 3.462s (427.5 samples/s);\n",
      "Finished Epoch[25 of 30]: [Training] loss = 0.013197 * 1480, metric = 0.20% * 1480 3.439s (430.4 samples/s);\n",
      "Finished Epoch[26 of 30]: [Training] loss = 0.013916 * 1480, metric = 0.27% * 1480 3.460s (427.7 samples/s);\n",
      "Finished Epoch[27 of 30]: [Training] loss = 0.014581 * 1480, metric = 0.14% * 1480 3.528s (419.5 samples/s);\n",
      "Finished Epoch[28 of 30]: [Training] loss = 0.014017 * 1480, metric = 0.27% * 1480 3.453s (428.6 samples/s);\n",
      "Finished Epoch[29 of 30]: [Training] loss = 0.012817 * 1480, metric = 0.14% * 1480 3.452s (428.7 samples/s);\n",
      "Finished Epoch[30 of 30]: [Training] loss = 0.017050 * 1480, metric = 0.41% * 1480 3.448s (429.2 samples/s);\n",
      "Stored trained model at /data/home/graeme/notebooks/openhack/Output/TransferLearning.model\n",
      "Done. Wrote output to /data/home/graeme/notebooks/openhack/Output/predictions.txt\n"
     ]
    }
   ],
   "source": [
    "base_folder = os.getcwd()\n",
    "\n",
    "# Model\n",
    "base_model_file = os.path.join(base_folder, 'CNTK', 'PretrainedModels', 'ResNet18_ImageNet_CNTK.model')\n",
    "\n",
    "# Data\n",
    "source_folder_path = os.path.join(base_folder, 'resized_images')\n",
    "train_folder_path = os.path.join(base_folder, 'train')\n",
    "validate_folder_path = os.path.join(base_folder, 'validate')\n",
    "\n",
    "# Output\n",
    "results_file = os.path.join(base_folder, \"Output\", \"predictions.txt\")\n",
    "new_model_file = os.path.join(base_folder, \"Output\", \"TransferLearning.model\")\n",
    "\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "num_channels = 3\n",
    "num_epochs = 30\n",
    "\n",
    "feature_node_name = \"features\"\n",
    "last_hidden_node_name = \"z.x\"\n",
    "file_endings = ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG']\n",
    "\n",
    "create_train_validate_folders(source_folder_path, train_folder_path, validate_folder_path, (image_width, image_height))\n",
    "\n",
    "try_set_default_device(gpu(0))\n",
    "\n",
    "model = train_and_eval(base_model_file, train_folder_path, validate_folder_path, results_file, new_model_file, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have successfully trained a new convolutional neural network model with an accuracy greater than 0.9, which is saved to ~/Output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, open TensorBoard to view a plot of training loss and validation loss. If you are using a Data Science Virtual Machine, after starting TensorBoard, add the port used by TensorBoard to the Network Security Group of your virtual machine, https://docs.microsoft.com/en-us/azure/virtual-machines/windows/nsg-quickstart-portal and access using the Public IP Address of your virtual machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir 'log'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue, interrupt the kernel to stop TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last task we need to score the five images that are not included in the ***gear*** dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_folder_path = os.path.join(base_folder, 'test')\n",
    "\n",
    "if (os.path.isdir(test_folder_path)) and (os.path.exists(test_folder_path)):\n",
    "    shutil.rmtree(test_folder_path)\n",
    "\n",
    "os.makedirs(test_folder_path)\n",
    "\n",
    "image_urls = []\n",
    "image_urls.append(('http://images.the-house.com/giro-g10mx-mtgy-07.jpg', 7))\n",
    "image_urls.append(('https://i.stack.imgur.com/HeliW.jpg', 0))\n",
    "image_urls.append(('https://productimages.camping-gear-outlet.com/e5/62379.jpg', 11))\n",
    "image_urls.append(('http://s7d1.scene7.com/is/image/MoosejawMB/MIKAJMKFMKCAPNABx1024698_zm?$product1000$', 2))\n",
    "image_urls.append(('http://www.buffalosystems.co.uk/wp-content/uploads/2012/06/zoom_apline_jacket_dark_russet-2365x3286.jpg', 5))\n",
    "\n",
    "size = (image_width, image_height)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Get the images and show the predicted classes\n",
    "for url_idx in range(len(image_urls)):\n",
    "    response = requests.get(image_urls[url_idx][0])\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "    \n",
    "    image_name = image_urls[url_idx][0].split('/')[-1]\n",
    "\n",
    "    if not '.jpg' in image_name:\n",
    "        image_name = '{0}.jpg'.format(image_name)\n",
    "        \n",
    "    image_path = os.path.join(test_folder_path, image_name)\n",
    "    \n",
    "    new_image = resize_image(image, size)\n",
    "    new_image.save(image_path)\n",
    "    \n",
    "    true_label = image_urls[url_idx][1]\n",
    "    class_mapping = create_class_mapping_from_folder(train_folder_path)\n",
    "    \n",
    "    probs = eval_single_image(model, image_path, image_width, image_height)\n",
    "    formatted_line = format_output_line(image_path, true_label, probs, class_mapping)\n",
    "    \n",
    "    a=fig.add_subplot(1, len(image_urls), url_idx + 1)\n",
    "    image_plot = plt.imshow(image)\n",
    "    a.set_title(formatted_line.split('{')[2].split(',')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(__-){"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
